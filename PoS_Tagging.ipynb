{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import necessary libraries\n"
      ],
      "metadata": {
        "id": "y1xXL2jdBdff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag, word_tokenize\n",
        "import nltk\n"
      ],
      "metadata": {
        "id": "_IZay8W4Bgp9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download necessary resources\n"
      ],
      "metadata": {
        "id": "C8dvIUnhBhjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "id": "ZUzaKoa_BjEp",
        "outputId": "42815a1a-58c4-419e-d6fc-41d680386624",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample sentence\n"
      ],
      "metadata": {
        "id": "EWP_F1sYBkEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"The quick brown fox jumps over the lazy dog.\"\n"
      ],
      "metadata": {
        "id": "OkTzhGvsBldA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Tokenize the sentence\n",
        "# Tokenization is the process of breaking down the text into individual words or tokens."
      ],
      "metadata": {
        "id": "dJA1CBrMBl5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = word_tokenize(sentence)\n",
        "print(\"Tokenized Words:\", words)"
      ],
      "metadata": {
        "id": "lz4mtx9oBq2O",
        "outputId": "4a090bd7-16d3-4f6c-daa1-c8b397f637bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized Words: ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Perform Part of Speech (PoS) tagging\n",
        "# PoS tagging assigns a part of speech to each word (e.g., noun, verb, adjective)."
      ],
      "metadata": {
        "id": "zVaGjcGwBsuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_words = pos_tag(words)\n",
        "print(\"\\nPoS Tagged Words:\", tagged_words)"
      ],
      "metadata": {
        "id": "i7SZQIfEBuQu",
        "outputId": "40fdcb6f-409b-46d8-94a7-b875e1168987",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PoS Tagged Words: [('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explanation:\n",
        "The output of pos_tag is a list of tuples, where each tuple contains a word and its corresponding PoS tag.\n",
        "Common PoS tags include:\n",
        " - NN: Noun\n",
        " - VB: Verb\n",
        " - JJ: Adjective\n",
        " - RB: Adverb\n",
        " - IN: Preposition"
      ],
      "metadata": {
        "id": "jgToAf0GByEp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Extract specific parts of speech\n",
        " Let's extract all nouns (NN) from the tagged words."
      ],
      "metadata": {
        "id": "FG1YwXy7B8de"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nouns = [word for word, pos in tagged_words if pos == 'NN']\n",
        "print(\"\\nNouns:\", nouns)"
      ],
      "metadata": {
        "id": "zzxtRMP1B94s",
        "outputId": "ca02d639-42e2-4988-9b5a-a064c78bb3e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Nouns: ['brown', 'fox', 'dog']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Count the occurrences of each PoS tag\n",
        "We can use a Counter to count how many times each PoS tag appears in the sentence."
      ],
      "metadata": {
        "id": "zwoKuYF2CAnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "pos_counts = Counter([pos for word, pos in tagged_words])\n",
        "print(\"\\nPoS Counts:\", pos_counts)"
      ],
      "metadata": {
        "id": "NTvpb5MxCCz1",
        "outputId": "753e8d27-2858-410d-ca96-1344fe13e9d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PoS Counts: Counter({'NN': 3, 'DT': 2, 'JJ': 2, 'VBZ': 1, 'IN': 1, '.': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Extract all verbs from the sentence\n",
        "Verbs can have different tags like VB, VBD (past tense), VBG (gerund), etc."
      ],
      "metadata": {
        "id": "W__OyoOXCEsD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ke_HUhQLAc_W",
        "outputId": "53e37161-f603-4b7e-ebc2-7b4925fb91ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Verbs: ['jumps']\n"
          ]
        }
      ],
      "source": [
        "verbs = [word for word, pos in tagged_words if pos.startswith('VB')]\n",
        "print(\"\\nVerbs:\", verbs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import necessary modules\n"
      ],
      "metadata": {
        "id": "nJ_k6hE8CZr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag, word_tokenize\n"
      ],
      "metadata": {
        "id": "J34LLTqACaFS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample sentence\n"
      ],
      "metadata": {
        "id": "0UGjpQb9CbGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"The quick brown fox jumps over the lazy dog.\"\n"
      ],
      "metadata": {
        "id": "-PxjEVcnCdWA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO: Tokenize the sentence and perform PoS tagging\n"
      ],
      "metadata": {
        "id": "Z5QsOidjCeRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_words = pos_tag(word_tokenize(sentence))"
      ],
      "metadata": {
        "id": "_MUmEuzHCfZI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO: Extract only the nouns (NN) from the tagged words\n"
      ],
      "metadata": {
        "id": "xeS1f0hnCiMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nouns = [word for word, pos in tagged_words if pos == 'NN']\n",
        "print(\"Nouns:\", nouns)"
      ],
      "metadata": {
        "id": "Jo29Q_XNCVw_",
        "outputId": "8b5ee910-3e63-41f3-e5b4-25e4fda02d85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nouns: ['brown', 'fox', 'dog']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import necessary modules\n"
      ],
      "metadata": {
        "id": "m7-jj2BLClGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag, word_tokenize\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "QrutpKbmCmZk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample sentence"
      ],
      "metadata": {
        "id": "Y814v2cECm1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"The quick brown fox jumps over the lazy dog.\"\n"
      ],
      "metadata": {
        "id": "bAotCj-TCqCb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO: Tokenize the sentence and perform PoS tagging\n"
      ],
      "metadata": {
        "id": "KMGD0NHSCsSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_words = pos_tag(word_tokenize(sentence))\n"
      ],
      "metadata": {
        "id": "KnffHvfxCtRt"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO: Count the occurrences of each PoS tag"
      ],
      "metadata": {
        "id": "fnVaIBJcCyhs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos_counts = Counter([pos for word, pos in tagged_words])\n",
        "print(\"PoS Counts:\", pos_counts)"
      ],
      "metadata": {
        "id": "JuTLsdYiCWS_",
        "outputId": "ca0ec270-b48c-4658-805c-75a85fa466db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PoS Counts: Counter({'NN': 3, 'DT': 2, 'JJ': 2, 'VBZ': 1, 'IN': 1, '.': 1})\n"
          ]
        }
      ]
    }
  ]
}